#!/usr/bin/env python3
"""
Universal File Analyzer - Test any file with complete PART 1-4 pipeline

Usage:
    python analyze_file.py <file_path>
    
Example:
    python analyze_file.py test_files/sample.pdf
    python analyze_file.py /path/to/any/file.ext
    
This script automatically detects the file type and runs complete analysis:
- PART 1: File Ingestion & Type Resolution
- PART 2: Deep File-Type-Aware Static Analysis
- PART 3: Rules, Correlation & Explainable Risk Scoring
- PART 4: Persistence, CLI & IPC (Data Durability Layer)
"""

import json
import sys
import tempfile
import os
from pathlib import Path
from src.file_analyzer.analyzer import analyze_file
from src.file_analyzer.deep_analyzer import deep_analyze_file
from src.file_analyzer.part3_analyzer import analyze_part3
from src.file_analyzer.part4.persistence import AnalysisDatabase
from src.file_analyzer.part4.exporter import Exporter, ExportFormat


def print_banner(text, char="="):
    """Print a formatted banner"""
    print("\n" + char * 80)
    print(text)
    print(char * 80)


def print_section(title):
    """Print a section header"""
    print("\n" + "=" * 80)
    print(f"Running {title}...")


def main():
    # Check if file path is provided
    if len(sys.argv) < 2:
        print("Error: File path required")
        print(f"\nUsage: python {sys.argv[0]} <file_path>")
        print("\nExamples:")
        print(f"  python {sys.argv[0]} test_files/sample.pdf")
        print(f"  python {sys.argv[0]} test_files/sample.txt")
        print(f"  python {sys.argv[0]} /path/to/any/file")
        sys.exit(1)
    
    file_path = sys.argv[1]
    
    # Validate file exists
    if not os.path.exists(file_path):
        print(f"Error: File not found: {file_path}")
        sys.exit(1)
    
    # Display header
    print_banner("UNIVERSAL FILE ANALYZER - COMPLETE ANALYSIS PIPELINE")
    print(f"\nAnalyzing: {file_path}")
    print(f"File size: {os.path.getsize(file_path)} bytes")
    
    try:
        # PART 1: File Ingestion & Type Resolution
        print_section("PART 1: File Ingestion & Type Resolution")
        part1 = analyze_file(file_path)
        
        # Extract key info from PART 1
        semantic_type = part1.get('summary', {}).get('semantic_file_type', 'UNKNOWN')
        container_type = part1.get('summary', {}).get('container_type', None)
        
        print(f"‚úÖ PART 1 Complete")
        print(f"   Semantic Type: {semantic_type}")
        print(f"   Container Type: {container_type or 'None'}")
        
        # PART 2: Deep File-Type-Aware Static Analysis
        print_section("PART 2: Deep File-Type-Aware Static Analysis")
        part2 = deep_analyze_file(file_path, part1)
        
        # Extract summary from PART 2
        total_findings = part2.get('summary', {}).get('total_findings', 0)
        
        print(f"‚úÖ PART 2 Complete")
        print(f"   Total Findings: {total_findings}")
        print(f"   Universal: {part2.get('summary', {}).get('universal_findings', 0)}")
        print(f"   Container: {part2.get('summary', {}).get('container_findings', 0)}")
        print(f"   File-Type Specific: {part2.get('summary', {}).get('file_type_specific_findings', 0)}")
        
        # PART 3: Rules, Correlation & Explainable Risk Scoring
        print_section("PART 3: Rules, Correlation & Explainable Risk Scoring")
        part3 = analyze_part3(file_path, part1, part2)
        
        # Extract risk score from PART 3
        risk_score = part3.get('risk_score', {}).get('normalized_score', 0)
        severity = part3.get('risk_score', {}).get('severity', 'unknown')
        heuristics_triggered = part3.get('heuristics', {}).get('heuristics_triggered', 0)
        
        print(f"‚úÖ PART 3 Complete")
        print(f"   Risk Score: {risk_score}/100")
        print(f"   Severity: {severity.upper()}")
        print(f"   Heuristics Triggered: {heuristics_triggered}")
        
        # PART 4: Persistence, CLI & IPC (Data Durability Layer)
        print_section("PART 4: Persistence, CLI & IPC")
        
        # Create temporary database for testing
        with tempfile.TemporaryDirectory() as tmpdir:
            db_path = Path(tmpdir) / "analysis.db"
            
            # Initialize database
            db = AnalysisDatabase(str(db_path))
            
            # Create a case and session
            case_id = db.create_case(
                name=f"Analysis of {Path(file_path).name}",
                description=f"Automated analysis of {semantic_type} file",
                metadata={
                    "analyst": "automated",
                    "file_type": semantic_type,
                    "original_path": file_path
                }
            )
            
            session_id = db.create_session(
                case_id=case_id,
                name=f"Session for {Path(file_path).name}",
                description=f"Analysis session created at {Path(file_path).parent}"
            )
            
            # Store analysis record
            record_id = db.import_analysis(
                session_id=session_id,
                part1_results=part1,
                part2_results=part2,
                part3_results=part3,
            )
            
            print(f"‚úÖ Analysis persisted to database")
            print(f"   Case ID: {case_id}")
            print(f"   Session ID: {session_id}")
            print(f"   Record ID: {record_id}")
            
            # Retrieve and verify
            retrieved_record = db.get_record(record_id)
            print(f"\n‚úÖ Analysis retrieved successfully")
            print(f"   File: {retrieved_record['file_path']}")
            print(f"   Created At: {retrieved_record['created_at']}")
            print(f"   Data integrity verified: ‚úì")
            
            # Export to JSON
            exporter = Exporter(db)
            export_path = Path(tmpdir) / f"{Path(file_path).stem}_analysis.json"
            exported_path = exporter.export_record(record_id, str(export_path), ExportFormat.JSON)
            
            print(f"\n‚úÖ Analysis exported to JSON")
            print(f"   Export path: {exported_path}")
            print(f"   Export size: {Path(exported_path).stat().st_size} bytes")
            
            # Query records
            session_analyses = db.query_records(session_id=session_id)
            print(f"\n‚úÖ Session query successful")
            print(f"   Records in session: {len(session_analyses)}")
            
            # Close database
            db.close()
            print(f"\n‚úÖ Database closed cleanly")
            
            # Store for final summary
            final_export_verified = Path(exported_path).exists()
        
        # Final Summary
        print_banner("ANALYSIS COMPLETE - ALL FOUR PARTS", "=")
        
        print(f"\nüìÑ File Information:")
        print(f"   Path: {file_path}")
        print(f"   Name: {Path(file_path).name}")
        print(f"   Size: {os.path.getsize(file_path)} bytes")
        
        print(f"\nüîç Analysis Results:")
        print(f"   Semantic Type: {semantic_type}")
        print(f"   Container Type: {container_type or 'None'}")
        print(f"   Total Findings: {total_findings}")
        
        print(f"\n‚ö†Ô∏è  Risk Assessment:")
        print(f"   Risk Score: {risk_score}/100")
        print(f"   Severity: {severity.upper()}")
        print(f"   Heuristics Triggered: {heuristics_triggered}")
        
        print(f"\nüíæ Persistence:")
        print(f"   Database Operations: 5/5 completed")
        print(f"   Export Operations: 1/1 completed")
        print(f"   Data Integrity: ‚úÖ Verified")
        
        # Status indicator
        if severity in ['critical', 'high']:
            status_emoji = "üî¥"
            status_text = "HIGH RISK"
        elif severity == 'medium':
            status_emoji = "üü°"
            status_text = "MEDIUM RISK"
        elif severity == 'low':
            status_emoji = "üü¢"
            status_text = "LOW RISK"
        else:
            status_emoji = "‚ö™"
            status_text = "INFORMATIONAL"
        
        print(f"\n{status_emoji} Overall Status: {status_text}")
        print("\n" + "=" * 80)
        
        # Exit with appropriate code
        if severity in ['critical', 'high']:
            sys.exit(2)  # High risk
        elif severity == 'medium':
            sys.exit(1)  # Medium risk
        else:
            sys.exit(0)  # Low risk or informational
            
    except Exception as e:
        print(f"\n‚ùå Error during analysis: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(3)


if __name__ == "__main__":
    main()
